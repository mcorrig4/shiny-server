---
title: "Ski Case"
output: html_notebook
---

## Load Data
```{r}
data.set <- read.csv("Whistler Blackcomb Exhibit1.csv", skip = 2)
data.set <- data.set[1:93, ]
colnames(data.set)[5] <- "Prebookings"
colnames(data.set)[6] <- "Actual.Demand"
colnames(data.set)[7] <- "Holiday"
colnames(data.set)[8] <- "Matched.DOW"
```


## Regression
#### Test Day-Matching Theory

Lets view the matched days as a time series
```{r}
library(plotly)
library(ggplot2)
names(data.set)
plot_ly(data.set, x = ~Day.of.Season, y = ~Actual.Demand, 
        name = 'Actual Demand', type = 'scatter', mode = 'lines') %>%
  add_trace(y = ~Matched.DOW, name = 'Matched Day', mode = 'lines+markers') 

```

Next Lets plot the days against eachother to see if there is some corrolation
```{r}
actualDemand <- data.set$Actual.Demand
matchedDemand <- data.set$Matched.DOW
plot(matchedDemand ~ actualDemand, 
     xlab = "Actual Demand", 
     ylab = "Past Demand 1998-1999", 
     main = "Demand Matched on Day of Week", 
     col = "blue")
m <- lm(matchedDemand ~ actualDemand)
abline(m, col="red")
legend(x='bottomright', legend=paste('Cor =',round(summary(m)$r.squared,2)))

```

Make a function to filter each day and see if certain days match up better
```{r}
library(dplyr)
filterDays <- function(df, days = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) {
  f <- filter(df, Day.of.Week == days)
  return(f)
}
```

Loop through the days of the week to see if any days match up better
```{r}
days <- c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")
for (i in 1:length(days)) {
  filtered <- filterDays(data.set, days[i])
  ad <- filtered$Actual.Demand
  md <- filtered$Matched.DOW
  plot(md ~ ad, 
     xlab = "Actual Demand", 
     ylab = "Past Demand 1998-1999", 
     main = paste("Demand Matched on", days[i]), 
     col = "blue")
  lm.filtered <- lm(md ~ ad)
  abline(lm.filtered, col="red")
  legend(x='bottomright', legend=paste('Cor =',round(summary(lm.filtered)$r.squared,2)))
}
```

It looks like the middle of the week has better day-matching correlation, lets map r^2 values to check
```{r}
r2Value <- NULL
for (i in 1:length(days)) {
  filtered <- filterDays(data.set, days[i])
  ad <- filtered$Actual.Demand
  md <- filtered$Matched.DOW
  lm.filtered <- lm(md ~ ad)
  r2 <- summary(lm.filtered)$r.squared
  r2Value <- c(r2Value, r2)
}
barplot(r2Value, main="R^2 Values", names.arg=days, cex.names=0.8)
```

The weekend definitely isn't a good time to use day matching to predict actual demand!!

```{r}
library(leaps)
names(data.set)
data.set$Prebookings
data.set$Actual.Demand
model.allsubsets <- regsubsets(Actual.Demand ~ Prebookings + Matched.DOW + 
                                 Exchange.Rate.USD.CAD + Exchange.Rate.GBP.CAD, 
                               data = data.set)
summary(model.allsubsets)
summary(model.allsubsets)$bic 
```


```{r}
#####example3
library(leaps)
# Reading Boston Housing data from upenn.edu
data = read.csv("http://stat.wharton.upenn.edu/~khyuns/stat431/BostonHousing.txt")
attach(data)

#All subsets
model.allsubsets = regsubsets((MEDV) ~ INDUSTRY + NROOMS + AGE + TAX + CRIM,data=data)
summary(model.allsubsets)
summary(model.allsubsets)$bic 

#forward selection
model.current = lm((MEDV) ~ 1)
add1(model.current,~INDUSTRY + NROOMS + AGE + TAX + CRIM,test="F")
# Choose the independent variable with the lowest p-value
model.current = lm((MEDV) ~ NROOMS)
add1( model.current,~INDUSTRY + NROOMS + AGE + TAX + CRIM,test="F")
# . etc..

#backward selection
model.current = lm((MEDV) ~ INDUSTRY + NROOMS + AGE + TAX + CRIM)
drop1(model.current,test="F")
# Choose the independent variable with the highest p-value
model.current = lm((MEDV) ~  NROOMS + AGE + TAX + CRIM)
drop1( model.current,test="F")
# ..etc..

#stepwise selection
null=lm((MEDV)~1, data=data)
full=lm((MEDV)~., data=data)
step(null, scope=list(lower=null, upper=full), direction="both")

```

```{r}
#####example 4: basketball team
#Historical data on new recruits for a basketball team .
#find the best model
bdata <- read.table("/Users/estefaniarv/Academic/Courses/Stats2017/5_6_Linear_regression/R/bball.csv", sep=",", header=TRUE)
bdata2 <- read.table("/Users/estefaniarv/Academic/Courses/Stats2017/5_6_Linear_regression/R/bball2.csv", sep=",", header=TRUE)
m0 <- lm(FGP ~ 1, data=bdata) #restricted model 
mall <- lm(FGP ~ GAMES + MPG + HGT + PPM + AGE + FTP, data=bdata) #full model
mbest <- step(m0, list(lower=m0, upper=mall), direction="both")

#Which player will you suggest to the owners that they hire? predict using mbest model with new data (in this case bdata2)
newFGP <- predict(mbest, bdata2,interval="prediction", level=0.95)

#What is the single variable that best predicts FGP?

```



library(Hmisc)
rcorr(as.matrix(bdata))



####################################
######### OUTLIERS

mydata <- within(data.frame(x=1:10), y <- rnorm(x, mean=x))
fm.orig <- lm(y ~ x, data=mydata)   
#create outlier
mydata$y[2] <- 20
fm.lm <- update(fm.orig)

#compare coefficients
coef(summary(fm.orig))
coef(summary(fm.lm))

#plot both models
plot(y ~ x, data=mydata)
abline(fm.orig, lty="dashed")    
abline(fm.lm)
legend("topright", inset=0.03, bty="n",
       legend = c("Without outlier", "With outlier"),
       lty = c("dashed", "solid")
)


#Use robust regression model
#Quantile regression
library("quantreg")                
fm.rq <- rq(y ~ x, data=mydata)

#Use iteratively re-weighted least squares fit
library("MASS")                 
fm.rlm <- rlm(y ~ x, data=mydata)

#Compare the models 
plot(y ~ x, data=mydata)
abline(fm.orig, lty="dashed")    # use a dashed line
abline(fm.lm)
abline(fm.rq, col="red")
abline(fm.rlm, col="blue")
legend("topright", inset=0.05, bty="n",
       legend = c("lm fit to original data", "lm fit", "rq fit", "rlm fit"),
       lty = c(2, 1, 1, 1),      # 1 = "solid" ; 2 = "dashed"
       col = c("black", "black", "red", "blue")
)


```

